PHP FRAMEWORK (повторное использование кода / масштабируемость / низкоуровневая безопасность приложения / следование MVС(разделение логики приложения и представление данных) и ООП / готовые формы и шаблоны /сокращение времени разработки / документация)
Yii (Yes it is)
Sympfony
Zend
Laravel
СodeIgniter

////////////
PSR0,4 про неймспейсы и автозагрузку
PSR1 про написание имен
PSR2 про скобки и пробелы при оформлении кода
PSR3 про ведение 8 логов (debug, info, notice, warning, error, critical, alert,emergency)

Автозагрузка: spl_autoload_register(callback) - регистрирует функцию (можно анонимную) в качестве автолоадера spl_autoload($className)
Автозагрузка в PHP отлично экономит время. Это позволяет писать скрипты не задумываясь о путях к библиотекам, которые вы используете. 

1)Cтандартная реализация: или проход по папкам проекта или ведение карты автозагрузки (и для использования класса надо было помнить лишь его имя)
2)Автозагрузка с неймспейсами и юзами(походит на джаву)(почти во всех современных фреймворсках)(надо очень хорошо знать классы фреймворка, чтобы использовать их и написать юз)
2+) пакетный менеджер Composer
Composer распространяется в виде одного файла composer.phar (phar — это php-архив) — по сути это PHP скприт, который может принимать несколько команд (install, update, ...) и умеет скачивать и распаковывать библиотеки.
(это так называемая локальная установка)

	пишем для проекта файлик composer.json (где указываем, откуда какие пакеты скачать композеру)(c packagist.org / оформленный и неоформленный пакет, файлы из репозиториев, просто архивы)
	для работы с проектом: качаем его(например, с гитхаба через clone)->запускаем композер в директории с проектом(php composer.phar install) (для обновления -update)
	композер сам создаст autoload.php (это единственно, че надо будет подключить: require "../vendor/autoload.php") и подгрузит пакеты


PSR
	PSR0: жесткое соответсвие неймспейса(и полного имени класса)  и пути до файла
	PSR4: нету жесткого соответсвия неймспейсу и пути до файла
 	namespace \неймспейс(хотя бы указать поставщика и пакет)\мб еще несколько субнеймспейсов\имя класса; (насчет _ и регистра все свободно, но главное че-нить одно)    
	(такой слеш \ для нэймспейсов юзов, а такой / для путей каталогов) cвоим названием неймспейс должен соответствовать(не точь-в-точь, а лишь на грани понимания):  базовый каталог/подкаталоги/класс
	namespace \Aura\Web\Response\Status ===> префикс неймспейса \Aura\Web cоответсвует базовому кадалогу path/to/aura-web/src, субнейспейс Response добавляет подкаталог, и вот полный путь path/to/aura-web/src/Response/Status.php



==========LINUX SENTOS(redhat64) BASH + YUM + GIT======================
По умолчанию в Linux=системе есть только самое необходимое, а если вам понадобится что-либо специфическое, то вам придется устанавливать программы вручную. 
Установка программ Linux в некотором смысле проще, чем в Windows. Здесь большинство необходимых программ находятся в официальных репозиториях и для их установки или обновления достаточно выполнить несколько команд.

YUM ( Yellowdog Updater Modified ) — это пакетный менеджер с открытым исходным кодом, разработанный в компании RedHat для работы с пакетами в формате RPM. 
С помощью него пользователи и системные администраторы могут устанавливать, удалять и обновлять пакеты в системах, основанных на RedHat.

редактор vi :   vi filename.txt -открытие/создание файла (для редактирования иногда требуется нажать insert)
для выхода+сохр жмешь ESC, внизу появится поле ввода, там набираешь :wq или просто :q

=========GIT=============
Git — это набор консольных утилит, которые отслеживают и фиксируют изменения в файлах(часто речь про код программ) / другие утилиты SVN, Mercurial, Perforce, CVS, Bitkeeper
(VCS version control system в PHPstorm)
Под линукс идут в составе дистрибутива, под винду прога gitforwindows
С его помощью вы можете делать контроль версий: откатиться на более старую версию вашего проекта, сравнивать, анализировать, сливать изменения и многое другое
Git является распределенным, не зависит от одного центрального сервера, на котором хранятся файлы.
он работает полностью локально, сохраняя данные в папках на жестком диске, которые называются репозиторием (есть и онлайн-хранилища, удобные для работы над одним проектом нескольких людей =>  github, bitbucket,..)

Установка
sudo yum install git
git --version (my is 1.8.3.1)
git config --global user.name "Ваше Имя"
git config --global user.email "you@example.com"
git config --list (проверить name и email)

======ЛОКАЛЬНЫЙ GIT==========
я @drive867 нахожусь в /home/drive867
mkdir /home/drive867/Рабочий\ стол/MyProjectWithGit
cd /home/drive867/Рабочий\ стол/MyProjectWithGit
git init (в директории создается скрытая папка .git, теперь будут трекаться все изменения)

git status

Сперва репозиторий пустой, но затем мы добавляем на него файлы (или части файлов, или даже одиночные строчки) командой add
git add hello.txt / git add -A (все файлы в папке)

Коммит представляет собой состояние репозитория в определенный момент времени. 
Это похоже на снапшот, к которому мы можем вернуться и увидеть состояние объектов на определенный момент времени.
Чтобы зафиксировать изменения, нам нужно хотя бы одно изменение в области выбранных файлов, после которого мы может коммитить:
git commit -m "My message to this commit"git


=============чисто сайт GITHUB===================
есть репозиторий с кодом (или создал свой)
есть master-branch, но можно делать побочные ветви, их коммитить, принимать обновы от родительских веток, 
на родительскую ветвь отправляются pull requests с тем, что было сделано (там можно смотреть и обсудждать что было сделано)
затем можно сделать слияние ветвей (при условии, что они не имеют конфликтов)

==========SSH для удобной авторизации к GITHUB (вместо введения пароля через HTTP)=====================
Смотрим имеющиеся ключи в папке .ssh 
	ls ~/.ssh
Создаем пару ключей (passphrase - eminem)
	ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
Добавляем ключи в SSH-агент
	eval $(ssh-agent -s)
	ssh-add ~/.ssh/[имя ключа, например id_rsa]
Копируем public key из файла id_rsa, добавляем его в аккаунт на гитхабе
Подключаемся
	ssh -T git@github.com
!!!! Под виндой ssh работает сразу, а в линуксе мб потребуется у репозитория исправить .git/.config (вместо https://github.com/user/repo.git)
	git remote set-url origin git@github.com:user/repo.git

==============GIT + GITHUB=========================

0) (удобно, когда ты уже что-то наделал локально и надо выгрузить еще и в сеть)
  создаешь новый онлайн-репозиторий (+убрать инициализацию Readme файлом, иначе в консоли стрельнет ошибку), получаешь ссылку типа https://github.com/drive867/Repository1
  у тебя уже должен быть локальный репозиторий
	mkdir /home/drive867/Рабочий\ стол/MyProjectWithGit
	cd /home/drive867/Рабочий\ стол/MyProjectWithGit
	git init
  подключаешь удаленный репозиторий. Проект может иметь несколько удаленных репозиториев одновременно. Обычно главный origin:
  	git remote add origin https://github.com/drive867/MyProjectWithGit1.git
  когда мы хотим отправить коммиты в онлайн-репозиторий, шлем запрос с его именем и веткой (потребуется SSH ключи или логиниться каждый раз drive867@gmail.com - swiz2121)
	git push -u origin master 	//произойдет загрузка коммитов на сервер, т.е где были изменения + новосозданных файлов

0*) (удобно, когда нужно выгрузить репозиторий из сети себе на комп)
  есть ссылка на чужой/свой онлайн-репозиторий типа https://github.com/drive867/MyProjectWithGit.git
  встаешь например на cd /home/drive867/Рабочий\ стол/ и делаешь
	git сlone https://github.com/drive867/MyProjectWithGit.git  //автоматом создастя локальный репозиторий + загрузкафайлов

1) через консоль делаешь cd до папки репозитория, можно глянуть статус 
	git status 
1) обновляешь состояние локального репозитория (синхронизация с удаленным репозиторием)
  получаем изменения с сервера с сохранением в каталог refs/remotes/ (то есть обновы пришли, но пока не слиты с нашим)
  Это никак не влияет на содержимое локального репозитория, его локальные ветки и текущие изменения.
	git fetch 
  Затем чтоб подгрузить недостающие данные из удаленного репозитория в локальную копию
	git merge
2) Смотришь ветви (видны только локальные ветки)
	git branch [origin]
2*) Можно вывести в консоль, че нового было с веткой (+загрузятся файлы с сайта на комп)
   по сути команда это git fetch +  git merge
	git pull [имяУдалРепозитория(ex.origin)] [(опционально)ИмяВетви(ex.master)]
2*) Можно начать новую ветвь(лучше всего делать ветку онлайн, потом fetch, потом локально создать ветку с тем же именем)
 //(все файлы созданные/измененные в ветке, не видны другим веткам)(как бы изоляция от момента создания ветки)
	git branch [newBranchName]
    Можно сменить текущую 
	 git checkout [selectedBranchName]
3) Локально чего-то делаешь в своем репозитории на своей ветке
4) выбираешь файлы, которые хочешь закоммитить или все cразу
	git add -A
5) Делаешь коммит изменений у выбранных файлов
	git commit -m "My message to this commit"
6) выгружаешь коммиты в онлайн-репозиторий
	git push -u [имяУдалРепозитория(ex.origin)] [ИмяВетви(ex.master)]
7*)cлияние(новые файлы от ребенка просто добавляются родителю)(если ребенок изменил файл родителя, а родитель не трогал - будет замена)(если ребенок удалил - то родителю тоже придется удалить)(если ребенок менял и родитель тоже менял - будет конфликт(нужны апдейты))
	выбрать родительскую ветку
 	git merge kid_branch
	git branch -d kid_branch / если ветка больше не нужна
	cделать push//хз почему, но ветка удаляется лишь локально, а на гитхабе остается


=============FPM & Nginx==================================
PHP FPM SAPI (Fast Process Manager ServerAPI) 
Работа с FPM отличается от работы с Apache в первую очередь тем, что FPM - это только PHP. Это не веб-сервер, не что-то умное. 
Это наоборот - максимально простой, легкий и быстрый, но довольно умный менеджер процессов для PHP. В отличие от апача тут даже не используется http
FPM контролирует количество работающих PHP-процессов, частоту их перезапуска для борьбы с утечками памяти (но модули php как и всегда текут) и прочие простые вещи, необходимые для контроля сервера.

Nginx - это http-proxy-server (отличие от апача, что это как бы не web-server, а проксисервер)
Nginx, сам не выполняет никакой тяжелой работы и на порядки быстрее обрабатывает запросы, чем любой другой сервер и потребляет при этом сильно меньше ресурсов. 
Nginx работает как конвеер - он просто быстро перекладывает запросы и ответы между backend и пользователями.

Для сравнения Apache. Запрос пришел от пользователя--> создался процесс на этот конкретный запрос --> ответ был отправлен --> процесс умер. (возможна атака группой длительных запросов)
Один рабочий процесс nginx - обрабатывает не один запрос пользователя, а тысячи этих запросов. nginx - это proxy-сервер, для него легко получить запрос пользователя и отправить его на backend (например php-fpm),
а пока бэкенд занят трудом, сервер обрабатывакт остальные запросы пользователей, когда FPM ответит Nginx-у о том что тот самый первый запрос обработан и отдаст ответ, nginx передаст ответ назад пользователю.
Это значит что мы можем одновременно обрабатывать 'x' запросов к динамике(через PHP-FPM), запросы же к статике(отдаем с диска) nginx разгребет своими силами в количестве '100x' одновременных почти на любой слабой VPS